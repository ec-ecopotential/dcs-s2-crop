{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2 crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'S2 Crop and GeoTiff conversion'),\n",
    "                ('abstract', 'Sentinel-2 crop and GeoTiff conversion'),\n",
    "                ('id', 's2_crop')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint = dict([('id', 'endpoint'),\n",
    "               ('value', 'https://catalog.terradue.com/sentinel2/search'),\n",
    "               ('title', 'Catalogue endpoint URL'),\n",
    "               ('abstract', 'Catalogue endpoint URL for dataset selection')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = dict([('id', 'start'),\n",
    "              ('value', '2018-05-05T10:00:00Z'),\n",
    "              ('title', 'start date for dataset selection'),\n",
    "              ('abstract', 'start date for dataset selection')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = dict([('id', 'stop'),\n",
    "            ('value', '2018-05-05T23:59:59Z'),\n",
    "            ('title', 'stop date for dataset selection'),\n",
    "            ('abstract', 'stop date for dataset selection')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_type = dict([('id', 'time_filter_type'),\n",
    "            ('value', 'date'),\n",
    "            ('title', 'search time filter type'),\n",
    "            ('abstract', 'search time filter type for dataset selection (date|update)')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_index = dict([('id', 'cat_index'),\n",
    "              ('value', 'ecop-cnr-issia'),\n",
    "              ('title', 'publishing catalog index'),\n",
    "              ('abstract', 'publishing catalog index')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_url = dict([('id', 'config_url'),\n",
    "                   ('value', 'https://store.terradue.com/ec-ecopotential/config/config.ini'),\n",
    "                   ('title', 'Configuration file URL'),\n",
    "                   ('abstract', 'Configuration file URL')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = dict([('id', 'username'),\n",
    "                 ('value', 'ecop-cnr-issia'),\n",
    "                 ('title', 'username for DA access'),\n",
    "                 ('abstract', 'username for DA access')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key  = dict([('id', 'api_key'),\n",
    "                 ('value', 'AKCp5aUjBi3JvjztBDdqPMMjM9beDhtcMLjGsn5axpviB3rAndimLeqfK3bTqUJsR2MtAkjiY'),\n",
    "                 ('title', 'apikey for DA access'),\n",
    "                 ('abstract', 'apikey for DA access')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_reference = \"camargue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifier = 'S2B_MSIL1C_20180609T103019_N0206_R108_T31TEJ_20180609T131037'\n",
    "#input_identifier = 'S2A_MSIL1C_20170909T110651_N0205_R137_T30STF_20170909T111217'\n",
    "#the last one actual area has no intersection with the AOI\n",
    "#input_identifier = 'S2A_MSIL1C_20180505T103021_N0206_R108_T31TFH_20180505T124726'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_config_url = 'https://store.terradue.com/ec-ecopotential/config/config.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import StringIO\n",
    "import configparser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    r = requests.get(input_config_url, headers={\"X-JFrog-Art-Api\":api_key['value'], 'User-Agent': 'curl/t2Client'})\n",
    "\n",
    "    ini_content = ''\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        ini_content = r.content\n",
    "\n",
    "    if not ini_content:\n",
    "        raise ValueError('No ini_content')\n",
    "\n",
    "        # read the configuration values\n",
    "    buf = StringIO.StringIO(ini_content)\n",
    "    config = configparser.ConfigParser()\n",
    "    config.readfp(buf)\n",
    "except Exception as e:\n",
    "    raise ValueError('Could not get config.ini : %s' %e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import snappy\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from os.path import basename\n",
    "import gdal\n",
    "import osr\n",
    "import zipfile\n",
    "\n",
    "import subprocess\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.path.count('/application/notebook/libexec/') == 0:\n",
    "    sys.path.append('/application/notebook/libexec/')\n",
    "sys.path.append(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftp_server = str(config.get('ftp', 'hostname'))\n",
    "base_path=str(config.get('ftp', 'base_path'))\n",
    "\n",
    "input_ftp_server_address = 'sftp://%s%s' %(ftp_server,base_path)\n",
    "\n",
    "pa_code = str(config.get(input_reference, 'pa_code'))\n",
    "pa_name = str(config.get(input_reference, 'pa_name'))\n",
    "#pa_bbox = str(config.get(input_reference, 'pa_bbox'))\n",
    "\n",
    "shapefile_url = str(config.get(input_reference, 'shapefile_url'))\n",
    "shapefile_url_crop = str(config.get(input_reference, 'shapefile_url_crop'))\n",
    "\n",
    "percentage_threshold = str(config.get(input_reference, 'percentage_threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2prd = \"%s/%s/%s.SAFE/MTD_MSIL1C.xml\" % (data_path, input_identifier, input_identifier)\n",
    "product = snappy.ProductIO.readProduct(s2prd)\n",
    "\n",
    "width = product.getSceneRasterWidth()\n",
    "height = product.getSceneRasterHeight()\n",
    "name = product.getName()\n",
    "description = product.getDescription()\n",
    "band_names = product.getBandNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_date = parser.parse(product.getStartTime().toString()).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_date = parser.parse(product.getStartTime().toString()).date()\n",
    "START_DATE = '%sZ' %parser.parse(product.getStartTime().toString()).isoformat()\n",
    "END_DATE = '%sZ' %parser.parse(product.getEndTime().toString()).isoformat()\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "metadata_date = now.strftime(\"%Y-%m-%d\")\n",
    "metadata_year = now.strftime(\"%Y\")\n",
    "\n",
    "creation_date = START_DATE\n",
    "\n",
    "date_path = '%s/%02d/%02d' % (product_date.year, product_date.month, product_date.day)\n",
    "    \n",
    "middle_path = '%s/EO_Data/Sentinel2/Raw'%pa_name\n",
    "        \n",
    "ftp_remote_path = os.path.join(input_ftp_server_address, date_path)\n",
    "zip_output_name = '%s_PA_%s_CROP.zip' % (name, pa_name)\n",
    "download_URL = '%s/%s' %(ftp_remote_path, zip_output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Shapefiles from store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from shapely.geometry import shape\n",
    "\n",
    "try:\n",
    "    for shpf_url in [shapefile_url,shapefile_url_crop]:\n",
    "        \n",
    "        for ext in ['prj','shp', 'shx', 'dbf', 'sbx', 'sbn']:\n",
    "        \n",
    "            shp_url = '%s.%s' %(shpf_url,ext)\n",
    "            r = requests.get(shp_url,headers={\"X-JFrog-Art-Api\":api_key['value'], 'User-Agent': 'curl/t2Client'})\n",
    "            \n",
    "            if r.status_code == 200 and r.content:\n",
    "                shapein = os.path.join(os.path.join(data_path,os.path.basename(shp_url)))\n",
    "                \n",
    "                with open(shapein,\"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=1024):\n",
    "                        # writing one chunk at a time to pdf file\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                    f.close()\n",
    "            else:\n",
    "                raise ValueError\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "shape_shp = os.path.join(os.path.join(data_path,os.path.basename('%s.shp' %shapefile_url)))\n",
    "shape_shp_crop = os.path.join(os.path.join(data_path,os.path.basename('%s.shp' %shapefile_url_crop)))\n",
    "\n",
    "shapeIN = shapefile.Reader(shape_shp)\n",
    "feature = shapeIN.shapeRecords()[0]\n",
    "first = feature.shape.__geo_interface__  \n",
    "\n",
    "shp_geom = shape(first)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud coverage analysis over the cropped area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snappy.GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('referenceBand', 'B1')\n",
    "\n",
    "resampleB1 = snappy.GPF.createProduct('Resample', parameters, product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "\n",
    "BandDescriptor = snappy.jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "\n",
    "targetBand0 = BandDescriptor()\n",
    "targetBand0.name = 'cloud_mask'\n",
    "targetBand0.type = 'uint16'\n",
    "targetBand0.expression = 'opaque_clouds_60m'\n",
    "\n",
    "\n",
    "targetBands = snappy.jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', 1)\n",
    "targetBands[0] = targetBand0\n",
    "\n",
    " \n",
    "parameters = HashMap()\n",
    "parameters.put('targetBands', targetBands)\n",
    "\n",
    "cloud_mask = snappy.GPF.createProduct('BandMaths', parameters, resampleB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WKTReader = snappy.jpy.get_type('com.vividsolutions.jts.io.WKTReader')\n",
    "\n",
    "geom = WKTReader().read(str(shp_geom))\n",
    "\n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('copyMetadata', True)\n",
    "parameters.put('geoRegion', geom)\n",
    "    \n",
    "try:\n",
    "    cloud_mask_geo = snappy.GPF.createProduct('Subset', parameters, cloud_mask)\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    cmg_bands = cloud_mask_geo.getNumBands()\n",
    "    cloud_percent = 100.0\n",
    "\n",
    "#if cmg_bands == 0:\n",
    "#    raise ValueError('NO intersection between AOI and actual dataset area') \n",
    "    \n",
    "if cmg_bands != 0:\n",
    "    mask_geo_output_name = '%s_%s_MASK_%s.tif' % (name, pa_code, '60')\n",
    "    snappy.ProductIO.writeProduct(cloud_mask_geo, mask_geo_output_name, 'GeoTIFF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cmg_bands != 0:\n",
    "    import gdalnumeric\n",
    "    raster_file = gdalnumeric.LoadFile(mask_geo_output_name)\n",
    "    #print raster_file.min(), raster_file.max()\n",
    "    pixel_count_cloud_geo = (raster_file == 255).sum()  # for pixel value = 1\n",
    "    #print pixel_count_cloud_geo\n",
    "    cloud_percent =  float(pixel_count_cloud_geo) / float(raster_file.size) * 100.0\n",
    "    #print 'cloud percent over cropped area: %s'%cloud_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cmg_bands != 0:\n",
    "    mask_output_name = '%s_MASK_%s.tif' % (name, '60')\n",
    "    snappy.ProductIO.writeProduct(cloud_mask, mask_output_name, 'GeoTIFF')\n",
    "    import gdalnumeric\n",
    "\n",
    "    raster_file = gdalnumeric.LoadFile(mask_output_name)\n",
    "\n",
    "    pixel_count_cloud = (raster_file == 255).sum()  # for pixel value = 1\n",
    "\n",
    "    cloud_percent_mask =  float(pixel_count_cloud) / float(raster_file.size) * 100.0\n",
    "    #print 'cloud percent over entire area: %s'%cloud_percent_mask\n",
    "    \n",
    "    loud_mask_geo = None\n",
    "    raster_file = None\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cloud_percent <= percentage_threshold and cmg_bands != 0:\n",
    "    \n",
    "    import shlex\n",
    "    import re\n",
    "    \n",
    "    bands_ref_list = ['B01', 'B02','B03','B04','B05','B06','B07','B08','B8A','B09','B10','B11','B12']\n",
    "    base_bands_path = '%s/%s/%s.SAFE/GRANULE/' % (data_path, input_identifier, input_identifier)\n",
    "    \n",
    "    pattern = re.compile(r'_B.*\\.jp2')\n",
    "\n",
    "    dataset_name = os.listdir(base_bands_path)\n",
    "    \n",
    "    bands_path = '%s%s/IMG_DATA' % (base_bands_path, dataset_name[0])\n",
    "\n",
    "    jp2_files = filter(lambda x: re.findall(pattern,x), os.listdir(bands_path))\n",
    "    n_files_orig = len(jp2_files)\n",
    "    jp2_basename = jp2_files[0].split('_B')[0]\n",
    "\n",
    "    jp2_files=dict()\n",
    "    for b in bands_ref_list:\n",
    "        jp2_files[b] = '%s_%s.jp2'%(jp2_basename,b)\n",
    "    n_files_new = len(jp2_files)\n",
    "    \n",
    "    assert (n_files_orig == n_files_new) , \"Cropping phase: Number of bands not corresponding to the expected ones\"\n",
    "    \n",
    "    geotiffs = dict()\n",
    "    \n",
    "    for b_name in bands_ref_list:\n",
    "\n",
    "        output_name = '%s_PA_%s_CROP_%s.tif' % (name, pa_name, b_name)\n",
    "        \n",
    "        band_in = '%s/%s' %(bands_path,jp2_files[b_name])\n",
    "        \n",
    "        #-tr 60.0 60.0 \n",
    "        cmd='/opt/anaconda/bin/gdalwarp -q -cutline %s -crop_to_cutline -co COMPRESS=LZW -of GTiff %s %s' %(shape_shp_crop, band_in, output_name)\n",
    "        \n",
    "        args = shlex.split(cmd)\n",
    "\n",
    "        try:\n",
    "            p = subprocess.Popen(args,\n",
    "                                 stdout=subprocess.PIPE,\n",
    "                                 stdin=subprocess.PIPE,\n",
    "                                 stderr=subprocess.PIPE)\n",
    "        except Exception, e:\n",
    "            #print 'An error occured while clippind data: %s' %e\n",
    "            raise Exception('An error occured while clippind data %s: \\n%s' %(output_name_tmp,e))\n",
    "\n",
    "        res, err = p.communicate()\n",
    "        if p.returncode:\n",
    "            raise Exception('Subprocess returned: %s \\n %s \\n on command %s' %(str(p.returncode), err, cmd))\n",
    "            \n",
    "        geotiffs[b_name] = output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotTiff(filename):\n",
    "\n",
    "    data = gdal.Open(filename)\n",
    "    bnd1 = data.GetRasterBand(1)\n",
    "\n",
    "    img1 = bnd1.ReadAsArray(0,0,data.RasterXSize, data.RasterYSize)\n",
    "    \n",
    "    imgplot = plt.imshow(img1, cmap=plt.cm.binary_r)    \n",
    "    \n",
    "    return imgplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotBand(product, band, vmin, vmax):\n",
    "    \n",
    "    band = product.getBand(band)\n",
    "\n",
    "    w = band.getRasterWidth()\n",
    "    h = band.getRasterHeight()\n",
    "    \n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    band.readPixels(0, 0, w, h, band_data)\n",
    "\n",
    "    band_data.shape = h, w\n",
    "\n",
    "    imgplot = plt.imshow(band_data, cmap=plt.cm.binary_r, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    \n",
    "    return imgplot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False and cmg_bands != 0:\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    for index, geotiff in enumerate(geotiffs):\n",
    "        a=fig.add_subplot(4,4,index+1)\n",
    "        imgplot = plotTiff(geotiff)\n",
    "        nameB = band_names[index]\n",
    "        a.set_title('%s %s-cropped' %(nameB, pa_name))\n",
    "    \n",
    "    a=fig.add_subplot(4,4,index+1)\n",
    "    imgplot = plotTiff(mask_geo_output_name)\n",
    "    a.set_title('cloud mask cropped')\n",
    "    \n",
    "    a=fig.add_subplot(4,4,index+2)\n",
    "    imgplot = plotTiff(mask_output_name)\n",
    "    a.set_title('cloud mask')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf() \n",
    "    plt.show()\n",
    "\n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_dates():\n",
    "    \n",
    "    iso_metadata.set_start_date(START_DATE)\n",
    "    iso_metadata.set_end_date(END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_info(short_name, title, abstract):\n",
    "    \n",
    "    iso_metadata.set_identifier(short_name)\n",
    "    iso_metadata.set_title(title)\n",
    "    iso_metadata.set_abstract(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_geo(band_name,geotiff):\n",
    "    \n",
    "    sp_i = dict()\n",
    "    ds = gdal.Open(geotiff)\n",
    "\n",
    "    iso_metadata.set_col_size(str(ds.RasterXSize))\n",
    "    iso_metadata.set_row_size(str(ds.RasterYSize))\n",
    "    sp_i['row_size'] = str(ds.RasterXSize)\n",
    "    sp_i['col_size'] = str(ds.RasterYSize)\n",
    "    \n",
    "    transform = ds.GetGeoTransform()\n",
    "    \n",
    "    sp_i['row_res'] = str(transform[1])\n",
    "    sp_i['col_res'] = str(transform[1])\n",
    "    \n",
    "    iso_metadata.set_pixel_size(str(transform[1]))\n",
    "\n",
    "    ul_x = transform[0]\n",
    "    ul_y = transform[3]\n",
    "\n",
    "    nw_corner = '%s %s' % (str(ul_x), str(ul_y))\n",
    "    sp_i['nw_corner'] = nw_corner\n",
    "\n",
    "    iso_metadata.set_nw_corner(nw_corner)\n",
    "\n",
    "    lr_x = transform[0] + transform[1] * ds.RasterXSize\n",
    "    lr_y = transform[3] + transform[5] * ds.RasterYSize\n",
    "\n",
    "    se_corner = '%s %s' % (str(lr_x), str(lr_y))\n",
    "    sp_i['se_corner'] = se_corner\n",
    "    \n",
    "    iso_metadata.set_se_corner(se_corner)\n",
    "        \n",
    "    old_cs= osr.SpatialReference()\n",
    "    old_cs.ImportFromWkt(ds.GetProjectionRef())\n",
    "\n",
    "    wgs84_wkt = \"\"\"\n",
    "GEOGCS[\"WGS 84\",\n",
    "    DATUM[\"WGS_1984\",\n",
    "        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "    PRIMEM[\"Greenwich\",0,\n",
    "        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    UNIT[\"degree\",0.01745329251994328,\n",
    "        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "    new_cs = osr.SpatialReference()\n",
    "    new_cs .ImportFromWkt(wgs84_wkt)\n",
    "\n",
    "    transform = osr.CoordinateTransformation(old_cs,new_cs) \n",
    "\n",
    "    min_lon = transform.TransformPoint(lr_x, ul_y)[0]\n",
    "    iso_metadata.set_min_lon(str(min_lon))\n",
    "\n",
    "    min_lat = transform.TransformPoint(ul_x,lr_y)[1]\n",
    "    iso_metadata.set_min_lat(str(min_lat))\n",
    "\n",
    "    max_lon = transform.TransformPoint(ul_x,lr_y)[0]\n",
    "    iso_metadata.set_max_lon(str(max_lon))\n",
    "\n",
    "    max_lat = transform.TransformPoint(lr_x, ul_y)[1]\n",
    "    iso_metadata.set_max_lat(str(max_lat))\n",
    "    \n",
    "    sp_i['min_lon'] = str(min_lon)\n",
    "    sp_i['min_lat'] = str(min_lat)\n",
    "    sp_i['max_lon'] = str(max_lon)\n",
    "    sp_i['max_lat'] = str(max_lat)\n",
    "    \n",
    "    prj = ds.GetProjection()\n",
    "    srs=osr.SpatialReference(wkt=prj)\n",
    "\n",
    "    sp_i['epsg_code'] = srs.GetAttrValue(\"PROJCS|AUTHORITY\", 1)\n",
    "    iso_metadata.set_epsg_code(srs.GetAttrValue(\"PROJCS|AUTHORITY\", 1))\n",
    "    \n",
    "    # adding single band spatial info to the global spatial info dict for the general ISOmetadata\n",
    "    spatial_info[band_name] = sp_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_properties(properties_file):\n",
    "    \n",
    "    properties = open(properties_file + '.properties', 'w')\n",
    "\n",
    "    properties.write('identifier=' + geotiff)\n",
    "    properties.write('\\n')\n",
    "    properties.write('date=%s/%s' % (START_DATE, END_DATE))\n",
    "    properties.write('\\n')\n",
    "    properties.write('category=%s,http://www.terradue.com/api/data-pipeline/results,%s Protected Area resource' % (pa_code, pa_name))\n",
    " \n",
    "    properties.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ISOMetadata\n",
    "\n",
    "#print dir(ISOMetadata.ISOMetadata())\n",
    "\n",
    "if cloud_percent <= percentage_threshold and cmg_bands != 0:\n",
    "    iso_metadata = ISOMetadata.ISOMetadata()\n",
    "    iso_metadata.set_contact('info@terradue.com')\n",
    "    iso_metadata.set_date(metadata_date)\n",
    "    iso_metadata.set_creation_date(creation_date)\n",
    "    iso_metadata.set_data_format('GEOTIFF')\n",
    "    iso_metadata.set_data_type('UInt16')\n",
    "    iso_metadata.set_pa(pa_name)\n",
    "    iso_metadata.set_data_quality('Nominal')\n",
    "    iso_metadata.set_responsible_party('CNR')\n",
    "    iso_metadata.set_onlineResource(download_URL)\n",
    "    lineage_template = 'Terradue [%s], Copernicus Sentinel data [%s]. \\\n",
    "This work has received funding from the European Union\\'s Horizon 2020 research and innovation programme \\\n",
    "under grant agreement No 641762 (ECOPOTENTIAL: improving future ecosystem benefits through earth observations).'\n",
    "    lineage_str = lineage_template %(str(metadata_year), str(product_date.year))\n",
    "    print lineage_str\n",
    "    iso_metadata.set_lineage_template(lineage_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cloud_percent <= percentage_threshold and cmg_bands != 0:\n",
    "\n",
    "    spatial_info = dict()\n",
    "    \n",
    "    for b_name in bands_ref_list:\n",
    "        \n",
    "        geotiff = geotiffs[b_name]\n",
    "        \n",
    "        set_dates()\n",
    "        \n",
    "        short_name = os.path.splitext(basename(geotiff))[0]\n",
    "        \n",
    "        title = 'Sentinel 2 Level 1C Band %s' % b_name\n",
    "        abstract = 'Sentinel 2 Level 1C Top of Atmosphere Reflectance for Band %s' % b_name\n",
    "        \n",
    "        set_info(short_name, title, abstract)\n",
    "\n",
    "        set_geo(b_name, geotiff)\n",
    "\n",
    "        iso_metadata.write(os.path.splitext(basename(geotiff))[0] + '.xml')\n",
    "\n",
    "        write_properties(basename(geotiff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipping the cropped bands and related metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cloud_percent <= percentage_threshold and cmg_bands != 0:  \n",
    "    \n",
    "    zip_output_name = '%s_PA_%s_CROP.zip' % (name, pa_name)\n",
    "    zf = zipfile.ZipFile(zip_output_name, mode='w')\n",
    "    try:\n",
    "        for b_name in bands_ref_list:\n",
    "        \n",
    "            geotiff = geotiffs[b_name]\n",
    "            \n",
    "            short_name = os.path.splitext(basename(geotiff))[0]\n",
    "            #print '%s %s.properties %s.xml' %(geotiff,geotiff,short_name)\n",
    "            zf.write(geotiff)\n",
    "            zf.write('%s.properties' %geotiff)\n",
    "            zf.write('%s.xml' %short_name)\n",
    "    finally:\n",
    "        #print 'closing'\n",
    "        zf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing General ISOMetadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cloud_percent <= percentage_threshold and cmg_bands != 0:\n",
    "    \n",
    "    short_name = os.path.splitext(zip_output_name)[0]\n",
    "    title = 'Sentinel 2 Level 1C %s (cropped Bands) ' % name\n",
    "    abstract = 'Sentinel 2 Level 1C Top of Atmosphere Reflectance for 13 Bands cropped over %s' % pa_name\n",
    "        \n",
    "    set_info(short_name, title, abstract)\n",
    "    \n",
    "    iso_metadata.set_spatialReprInfo_elems(spatial_info, bands_ref_list)\n",
    "\n",
    "    iso_metadata.set_spatial_resolutions([str(10),str(20),str(60)])\n",
    "    \n",
    "    iso_metadata.set_lineage_template(lineage_str)\n",
    "    \n",
    "    iso_metadata.set_min_lon(spatial_info['B01']['min_lon'])\n",
    "    iso_metadata.set_min_lat(spatial_info['B01']['min_lat'])\n",
    "    iso_metadata.set_max_lon(spatial_info['B01']['max_lon'])\n",
    "    iso_metadata.set_max_lat(spatial_info['B01']['max_lat'])\n",
    "    \n",
    "    iso_metadata.write(os.path.splitext(zip_output_name)[0] + '.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
